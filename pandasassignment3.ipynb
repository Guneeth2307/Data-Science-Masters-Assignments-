{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e348e215-fa15-4c57-a21e-1a55a1cc046c",
   "metadata": {},
   "source": [
    "                                              Pandas Assignment-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1de2c12-ab98-42a3-a29d-3aa57e6a45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {'course_name' : course_name, 'duration' : duration})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d068a64-dcc1-40f6-af41-f9d96c54400e",
   "metadata": {},
   "source": [
    "Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6054af9-064a-4084-820d-4cacf942d6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e06d84-1b61-497b-9f7f-044212072b94",
   "metadata": {},
   "source": [
    "Q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bc611b-9e04-4a6a-8778-1d08e86fdd67",
   "metadata": {},
   "source": [
    "loc (label-based selection):\n",
    "\n",
    "It is primarily used for selecting data based on labels (row and column names).\n",
    "When using loc, you specify the labels (names) of the rows and columns you want to access.\n",
    "It includes the endpoint, which means the last label is included in the selection.\n",
    "You can use label-based slicing or provide a single label to select specific rows or columns.\n",
    "\n",
    "iloc (integer-based selection):\n",
    "\n",
    "It is used for selecting data based on integer positions (row and column indices).\n",
    "When using iloc, you specify the integer indices of the rows and columns you want to access.\n",
    "It follows the typical Python-style 0-based indexing, where the first item is at index 0.\n",
    "It does not include the endpoint, meaning the last integer index is not included in the selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377f3a38-adb5-4032-bcee-43eb133757b0",
   "metadata": {},
   "source": [
    "Q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a37f2b61-cd58-4de8-9060-1e3fe4936f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for new_df.loc[2]:\n",
      "course_name    Big Data\n",
      "duration              6\n",
      "Name: 2, dtype: object\n",
      "\n",
      "Output for new_df.iloc[2]:\n",
      "course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Original DataFrame\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2, 3, 6, 4]\n",
    "df = pd.DataFrame(data={'course_name': course_name, 'duration': duration})\n",
    "\n",
    "# Reindex the DataFrame using the variable 'reindex'\n",
    "reindex = [3, 0, 1, 2]\n",
    "new_df = df.reindex(reindex)\n",
    "\n",
    "# Output for new_df.loc[2] and new_df.iloc[2]\n",
    "output_loc = new_df.loc[2]\n",
    "output_iloc = new_df.iloc[2]\n",
    "\n",
    "print(\"Output for new_df.loc[2]:\")\n",
    "print(output_loc)\n",
    "\n",
    "print(\"\\nOutput for new_df.iloc[2]:\")\n",
    "print(output_iloc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7effd158-c69e-4b64-ae68-fa4ec1c2f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "#Creating a dataframe:\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865a7ed1-0e9f-49d7-a3cf-f768c129af32",
   "metadata": {},
   "source": [
    "Q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26377786-6382-48a9-afb7-1a5129c808e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of each column:\n",
      "column_1    0.439248\n",
      "column_2    0.376140\n",
      "column_3    0.479446\n",
      "column_4    0.572360\n",
      "column_5    0.652885\n",
      "column_6    0.624556\n",
      "dtype: float64\n",
      "\n",
      "Standard deviation of 'column_2': 0.35161927996095216\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Creating a DataFrame with random data\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# (i) Calculate the mean of each column\n",
    "column_means = df1.mean()\n",
    "print(\"Mean of each column:\")\n",
    "print(column_means)\n",
    "\n",
    "# (ii) Calculate the standard deviation of 'column_2'\n",
    "std_column_2 = df1['column_2'].std()\n",
    "print(\"\\nStandard deviation of 'column_2':\", std_column_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d22aa-360c-402e-a4be-49f846962b35",
   "metadata": {},
   "source": [
    "Q5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed1f66c3-bd0b-44bd-b781-8eb8188a32ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m df1\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis is a string\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Attempt to calculate the mean of 'column_2' (this will result in an error)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m mean_column_2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumn_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11847\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11829\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11830\u001b[0m     _num_doc,\n\u001b[1;32m  11831\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11845\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11846\u001b[0m ):\n\u001b[0;32m> 11847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11401\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11395\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11399\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11400\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11402\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  11344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  11345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11348\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11349\u001b[0m     )\n\u001b[1;32m  11350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11351\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11352\u001b[0m     )\n\u001b[0;32m> 11353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4813\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4814\u001b[0m     )\n\u001b[1;32m   4815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    421\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:706\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    703\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    705\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m--> 706\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    709\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "# Replace the data in the second row of 'column_2' with a string variable\n",
    "df1.loc[2, 'column_2'] = 'This is a string'\n",
    "\n",
    "# Attempt to calculate the mean of 'column_2' (this will result in an error)\n",
    "mean_column_2 = df1['column_2'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3654dec9-4eb3-4744-9b8d-e00efe2025e8",
   "metadata": {},
   "source": [
    "Q6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7f5bd5-a7a0-4c03-9e20-29e883891292",
   "metadata": {},
   "source": [
    "In pandas, the \"window functions\" refer to a set of functions that allow you to perform calculations over a sliding or rolling window of data in a DataFrame or Series. These functions are particularly useful for time series data and can be used to calculate various statistical and analytical measures over a specified window of data points.\n",
    "\n",
    "Some common window functions in pandas include:\n",
    "\n",
    "1. `rolling()`: This function creates a rolling view of a DataFrame or Series, allowing you to perform rolling window operations like mean, sum, and more. You can specify the window size and apply functions to it. Example:\n",
    "\n",
    "   ```python\n",
    "   df['rolling_mean'] = df['column'].rolling(window=3).mean()\n",
    "   ```\n",
    "\n",
    "2. `expanding()`: The expanding window function calculates cumulative statistics as the window expands. It includes all data points up to the current row. Example:\n",
    "\n",
    "   ```python\n",
    "   df['cumulative_sum'] = df['column'].expanding().sum()\n",
    "   ```\n",
    "\n",
    "3. `ewm()`: Exponentially Weighted Moving Average (EWMA) is used for calculating weighted moving averages, where more recent values are given more weight. Example:\n",
    "\n",
    "   ```python\n",
    "   df['ewma'] = df['column'].ewm(span=5).mean()\n",
    "   ```\n",
    "\n",
    "4. `rolling_apply()`: You can use this function to apply custom functions over rolling windows. Example:\n",
    "\n",
    "   ```python\n",
    "   def custom_function(window):\n",
    "       return window.max() - window.min()\n",
    "   \n",
    "   df['custom_window_function'] = df['column'].rolling(window=3).apply(custom_function)\n",
    "   ```\n",
    "\n",
    "5. `rolling_corr()`: This function is used to compute the rolling correlation between two Series. Example:\n",
    "\n",
    "   ```python\n",
    "   df['rolling_corr'] = df['column1'].rolling(window=3).corr(df['column2'])\n",
    "   ```\n",
    "\n",
    "6. `rolling_cov()`: Similar to `rolling_corr()`, this function calculates the rolling covariance between two Series.\n",
    "\n",
    "These window functions are essential for time series analysis and can help you calculate various statistics and moving averages over a specified window of data, making it easier to extract meaningful insights from your data. Depending on your analysis needs, you can choose the appropriate window function and customize it to suit your requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b35bef-a4cd-46b1-97bd-e4c4da24ced3",
   "metadata": {},
   "source": [
    "Q7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17423b10-f0ae-4fc7-a6f9-3339daa71bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current month: 11\n",
      "Current year: 2023\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_date = datetime.now()\n",
    "\n",
    "# Extract the current month and year\n",
    "current_month = current_date.month\n",
    "current_year = current_date.year\n",
    "\n",
    "# Print the current month and year\n",
    "print(\"Current month:\", current_month)\n",
    "print(\"Current year:\", current_year)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949dc8c6-2c9f-42ab-9d9a-fd24b1f9bb67",
   "metadata": {},
   "source": [
    "Q8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92b7d55-4bf5-43be-8e65-39ba6acce1c9",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate the date difference\n",
    "def calculate_date_difference(start_date, end_date):\n",
    "    # Convert the input strings to datetime objects\n",
    "    start_datetime = pd.to_datetime(start_date)\n",
    "    end_datetime = pd.to_datetime(end_date)\n",
    "    \n",
    "    # Calculate the time difference\n",
    "    time_difference = end_datetime - start_datetime\n",
    "    \n",
    "    # Extract days, hours, and minutes\n",
    "    days = time_difference.days\n",
    "    hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "    minutes = remainder // 60\n",
    "    \n",
    "    return days, hours, minutes\n",
    "\n",
    "# Get input from the user\n",
    "start_date = input(\"Enter the start date (YYYY-MM-DD): \")\n",
    "end_date = input(\"Enter the end date (YYYY-MM-DD): \")\n",
    "\n",
    "# Calculate the date difference\n",
    "days, hours, minutes = calculate_date_difference(start_date, end_date)\n",
    "\n",
    "# Display the result\n",
    "print(f\"Date Difference: {days} days, {hours} hours, {minutes} minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b465af0a-b706-4ea1-848e-3808b4ef50e9",
   "metadata": {},
   "source": [
    "Q9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477bb91e-75dd-4562-bff4-58721d9d4744",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to convert a specified column to a categorical data type\n",
    "def convert_column_to_categorical(df, column_name, category_order):\n",
    "    if column_name not in df.columns:\n",
    "        print(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "        return df\n",
    "\n",
    "    df[column_name] = pd.Categorical(df[column_name], categories=category_order, ordered=True)\n",
    "    return df\n",
    "\n",
    "# Function to sort and display the DataFrame\n",
    "def sort_and_display(df, column_name):\n",
    "    sorted_df = df.sort_values(by=column_name)\n",
    "    print(sorted_df)\n",
    "\n",
    "# Prompt the user for the file path\n",
    "file_path = input(\"Enter the CSV file path: \")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"\\nFirst few rows of the DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Prompt the user for the column name to convert\n",
    "column_name = input(\"Enter the column name to convert to categorical: \")\n",
    "\n",
    "# Prompt the user for the custom category order (comma-separated)\n",
    "category_order = input(\"Enter the custom category order (comma-separated): \").split(',')\n",
    "\n",
    "# Convert the specified column to a categorical data type\n",
    "df = convert_column_to_categorical(df, column_name, category_order)\n",
    "\n",
    "# Sort and display the DataFrame with the specified column\n",
    "if df is not None:\n",
    "    print(f\"\\nDataFrame sorted by '{column_name}':\")\n",
    "    sort_and_display(df, column_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011e4bab-7ac5-41b3-8a59-d4d3920f5df0",
   "metadata": {},
   "source": [
    "Q10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933c4a24-f6a7-4985-b03a-2e6980839d4c",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prompt the user for the CSV file path\n",
    "file_path = input(\"Enter the CSV file path: \")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# Assuming your CSV file has a structure like:\n",
    "# Date, Product_Category, Sales\n",
    "# 2023-01-01, A, 100\n",
    "# 2023-01-01, B, 150\n",
    "# ...\n",
    "\n",
    "# Pivot the DataFrame to have Product_Category as columns and Date as the index\n",
    "pivot_df = df.pivot(index='Date', columns='Product_Category', values='Sales')\n",
    "\n",
    "# Create a stacked bar chart\n",
    "pivot_df.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "\n",
    "# Customize the plot (you can further customize as needed)\n",
    "plt.title('Stacked Bar Chart of Sales by Product Category Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.legend(title='Product Category')\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe31f6a-f5db-4d0d-9de7-8dadcb1520fd",
   "metadata": {},
   "source": [
    "Q11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef23d45-4f9d-4f33-a8c9-e438a2d58a67",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prompt the user for the CSV file path\n",
    "file_path = input(\"Enter the file path of the CSV file containing student data: \")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# Calculate the mean, median, and mode of the test scores\n",
    "mean_score = df['Test Score'].mean()\n",
    "median_score = df['Test Score'].median()\n",
    "mode_scores = df['Test Score'].mode()\n",
    "\n",
    "# Display the results in a table\n",
    "result_table = pd.DataFrame({\n",
    "    'Statistic': ['Mean', 'Median', 'Mode'],\n",
    "    'Value': [mean_score, median_score, ', '.join(map(str, mode_scores))]\n",
    "})\n",
    "\n",
    "# Print the table\n",
    "print(result_table.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4277b0f9-85d1-4711-87f0-02c8e56291d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
